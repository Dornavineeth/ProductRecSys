# -*- coding: utf-8 -*-
"""EDA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1D1Sv-ACdq5EyYEWFO_HTu1CoJ1NGNqkr
"""

import time
import numpy as np
import pandas as pd
from collections import defaultdict
from argparse import ArgumentParser
from sklearn.model_selection import train_test_split

# %matplotlib inline
from surprise import Reader
from surprise import Dataset
from surprise import accuracy
from surprise import KNNWithMeans
from sklearn.preprocessing import LabelEncoder
from surprise.model_selection import train_test_split


def parse_args():
    parser = ArgumentParser(description='Recommendation System')
    parser.add_argument('--num_threads', type=str, default='1')
    parser.add_argument('--model_dir', type=str, default='output')
    parser.add_argument('--data_path', type=str, required=True)
    return parser.parse_known_args()[0]

def precision_recall_at_k(predictions, k=10, threshold=0.0):
    """Return precision and recall at k metrics for each user"""

    # First map the predictions to each user.
    user_est_true = defaultdict(list)
    for uid, _, true_r, est, _ in predictions:
        user_est_true[uid].append((est, true_r))

    precisions = dict()
    recalls = dict()
    for uid, user_ratings in user_est_true.items():

        # Sort user ratings by estimated value
        user_ratings.sort(key=lambda x: x[0], reverse=True)

        # Number of relevant items
        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)

        # Number of recommended items in top k
        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])

        # Number of relevant and recommended items in top k
        n_rel_and_rec_k = sum(
            ((true_r >= threshold) and (est >= threshold))
            for (est, true_r) in user_ratings[:k]
        )

        # Precision@K: Proportion of recommended items that are relevant
        # When n_rec_k is 0, Precision is undefined. We here set it to 0.

        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0

        # Recall@K: Proportion of relevant items that are recommended
        # When n_rel is 0, Recall is undefined. We here set it to 0.

        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0

    return np.mean(list(precisions.values())), np.mean(list(recalls.values()))


def train(args):
    data_path = args.data_path

    df = pd.read_csv(data_path)
    df.drop(['reviewTime'], axis=1,inplace=True)
    df.drop(['verified'], axis=1,inplace=True)
    # Assuming 'nd' is your pandas dataframe
    le = LabelEncoder()
    for column in df.columns:
        if column != 'rating':
            df[column + '_index'] = le.fit_transform(df[column])

    # Display the transformed DataFrame
    df.drop(['reviewerID'], axis=1,inplace=True)
    df.drop(['productID'], axis=1,inplace=True)
    df = df[['reviewerID_index', 'productID_index','rating']]
    reader = Reader(rating_scale=(1, 5))
    data = Dataset.load_from_df(df,reader)
    # import pdb;pdb.set_trace()
    trainset, testset = train_test_split(data, test_size=0.2,random_state=0)
    # import pdb;pdb.set_trace()
    start_time = time.time()
    algo = KNNWithMeans(k=40, min_k=40, sim_options={'user_based': True})
    algo.fit(trainset)
    print("Total Time : ", time.time()-start_time)
    test_pred = algo.test(testset)
    rmse = accuracy.rmse(test_pred, verbose=True)
    # import pdb;pdb.set_trace()
    print("RMSE="+str(rmse))

    # prec_5, recall_5 = precision_recall_at_k(test_pred, k=5, threshold=3.5)
    # prec_10, recall_10 = precision_recall_at_k(test_pred, k=10, threshold=3.5)
    # prec_50, recall_50 = precision_recall_at_k(test_pred, k=50, threshold=3.5)

    print("Precision@5="+str(prec_5))
    print("Precision@10="+str(prec_10))
    print("Precision@50="+str(recall_50))
    print("Recall@5="+str(recall_5))
    print("Recall@10="+str(recall_10))
    print("Recall@50="+str(recall_50))

if __name__ == '__main__':
    args = parse_args()
    print(args)
    train(args)




